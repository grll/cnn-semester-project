{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "from functools import partial\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up pickle to support encoding of the trained 2.7 weight\n",
    "pickle.load = partial(pickle.load, encoding=\"latin1\")\n",
    "pickle.Unpickler = partial(pickle.Unpickler, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define our transformation function\n",
    "centre_crop = transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.35s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# load the data with cocoAPI\n",
    "cap = dset.CocoCaptions(root = '/home/raille/coco-features/coco-dataset/train2017',\n",
    "                        annFile = '/home/raille/coco-features/coco-dataset/annotations/captions_train2017.json',\n",
    "                        transform=centre_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataloader to iterate over the dataset in batch of images\n",
    "batch_size = 4\n",
    "dataloders = torch.utils.data.DataLoader(cap, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raille/anaconda3/lib/python3.6/site-packages/torch/serialization.py:286: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "arch = 'resnet18'\n",
    "\n",
    "model_file = 'whole_%s_places365.pth.tar' % arch\n",
    "if not os.access(model_file, os.W_OK):\n",
    "    weight_url = 'http://places2.csail.mit.edu/models_places365/whole_%s_places365.pth.tar' % arch\n",
    "    os.system('wget ' + weight_url)\n",
    "\n",
    "useGPU = torch.cuda.is_available()\n",
    "if useGPU == 1:\n",
    "    model = torch.load(model_file)\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    model = torch.load(model_file, map_location=lambda storage, loc: storage, pickle_module=pickle) # model trained in GPU could be deployed in CPU machine like this!\n",
    "\n",
    "# put the model in eval mode (no dropout / batchnorm...)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a custom forward function to get only the final features just before the fc\n",
    "def my_forward(x):\n",
    "    x = model.conv1(x)\n",
    "    x = model.bn1(x)\n",
    "    x = model.relu(x)\n",
    "    x = model.maxpool(x)\n",
    "\n",
    "    x = model.layer1(x)\n",
    "    x = model.layer2(x)\n",
    "    x = model.layer3(x)\n",
    "    x = model.layer4(x)\n",
    "\n",
    "    x = model.avgpool(x)\n",
    "    # reshape the tensor into a #images * n vector\n",
    "    x = x.view(x.size(0), -1)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a FloatTensor to gather all the features\n",
    "if useGPU:\n",
    "    features = torch.cuda.FloatTensor(len(cap), 512)\n",
    "else:\n",
    "    features = torch.FloatTensor(len(cap), 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the pretrained model on the data and put the collected feature in the features tensor\n",
    "for i, data in enumerate(dataloders):\n",
    "    inputs, captions = data\n",
    "\n",
    "    if useGPU:\n",
    "        inputs = V(inputs.cuda())\n",
    "    else:\n",
    "        inputs = V(inputs)\n",
    "\n",
    "    features[i*batch_size:(i+1)*batch_size] = my_forward(inputs).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the raw features extracted\n",
    "torch.save(features, 'raw-features-scaled.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "# Perform the standardization of the data\n",
    "for i in range(features.shape[1]):\n",
    "    features[:, i].add_(-torch.mean(features[:, i]))\n",
    "    features[:, i].div_(torch.std(features[:, i]))\n",
    "    \n",
    "# Perform SVD\n",
    "U, S, V = torch.svd(features)\n",
    "\n",
    "# Keep only the principal component\n",
    "k = 128\n",
    "PC_k = torch.mm(U[:, 0:k], torch.diag(S)[0:k,0:k])\n",
    "\n",
    "# save the reduced matrice\n",
    "torch.save(PC_k, 'PCA-features-scaled.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
